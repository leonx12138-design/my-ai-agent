/**
 * AI Agent æ ¸å¿ƒå®ç°
 * åŸºäº Claude Code çš„ nO ä¸»å¾ªç¯è®¾è®¡
 */

import { MessageQueue } from './message-queue.js';

class AIAgent {
  constructor(config = {}) {
    this.messageQueue = new MessageQueue();
    this.llmApiKey = config.apiKey || process.env.LLM_API_KEY;
    this.llmBaseUrl = config.baseUrl || 'https://open.bigmodel.cn/api/paas/v4/chat/completions';
    this.modelName = config.model || 'glm-4-flash';  // æ™ºè°±å…è´¹æ¨¡å‹
    this.conversationHistory = [];
  }

  /**
   * Agent ä¸»å¾ªç¯ - å‚è€ƒ nO å‡½æ•°è®¾è®¡
   */
  async* run() {
    console.log('ğŸ¤– AI Agent å¯åŠ¨...\n');

    for await (const message of this.messageQueue) {
      console.log(`ğŸ‘¤ ç”¨æˆ·: ${message}`);

      // æ·»åŠ åˆ°å¯¹è¯å†å²
      this.conversationHistory.push({
        role: 'user',
        content: message
      });

      // è°ƒç”¨ LLM
      try {
        const response = await this.callLLM();
        console.log(`ğŸ¤– åŠ©æ‰‹: ${response}\n`);

        // æ·»åŠ åˆ°å†å²
        this.conversationHistory.push({
          role: 'assistant',
          content: response
        });

        yield response;
      } catch (error) {
        console.error('âŒ LLM è°ƒç”¨å¤±è´¥:', error.message);
        yield 'æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚';
      }
    }

    console.log('âœ… å¯¹è¯ç»“æŸ');
  }

  /**
   * è°ƒç”¨ LLM API
   */
  async callLLM() {
    if (!this.llmApiKey) {
      return 'æç¤ºï¼šè¯·è®¾ç½® LLM_API_KEY ç¯å¢ƒå˜é‡æˆ–åœ¨é…ç½®ä¸­æä¾› apiKeyã€‚\nä½ å¯ä»¥åœ¨ https://open.bigmodel.cn/ æ³¨å†Œè·å–å…è´¹ API Keyã€‚';
    }

    const response = await fetch(this.llmBaseUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.llmApiKey}`
      },
      body: JSON.stringify({
        model: this.modelName,
        messages: this.conversationHistory,
        temperature: 0.7
      })
    });

    if (!response.ok) {
      throw new Error(`API è¯·æ±‚å¤±è´¥: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  /**
   * å‘é€ç”¨æˆ·æ¶ˆæ¯
   */
  sendMessage(message) {
    this.messageQueue.enqueue(message);
  }

  /**
   * ç»“æŸå¯¹è¯
   */
  end() {
    this.messageQueue.done();
  }
}

// ============ æ¼”ç¤ºç¨‹åº ============

async function demo() {
  // åˆ›å»º AI Agent
  const agent = new AIAgent({
    // apiKey: 'ä½ çš„APIå¯†é’¥',  // å–æ¶ˆæ³¨é‡Šå¹¶å¡«å…¥ä½ çš„ API Key
  });

  // å¯åŠ¨ Agent
  const agentTask = (async () => {
    for await (const response of agent.run()) {
      // Agent å“åº”å·²ç»åœ¨ run() ä¸­æ‰“å°äº†
    }
  })();

  // æ¨¡æ‹Ÿç”¨æˆ·äº¤äº’
  await sleep(1000);
  agent.sendMessage('ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±');

  await sleep(3000);
  agent.sendMessage('ä½ èƒ½å¸®æˆ‘åšä»€ä¹ˆï¼Ÿ');

  await sleep(3000);
  agent.sendMessage('è°¢è°¢ï¼');

  await sleep(2000);
  agent.end();

  // ç­‰å¾… Agent å®Œæˆ
  await agentTask;
}

function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

// è¿è¡Œæ¼”ç¤º
demo().catch(console.error);
